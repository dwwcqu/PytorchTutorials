{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuHTXllnLi7u"
      },
      "source": [
        "# 5.1.4 Linear Regression(线性回归)\n",
        "\n",
        "我们对机器学习算法的定义是能够通过经验，提高计算机程序在某些任务上的表现的算法，这种定义有些抽象。为了更具体一点，我们给出了一个简单的机器学习算法的例子：线性回归。在介绍更多有助于理解其行为的机器学习概念时，我们将反复回到这个例子。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVgbfPhkLmMJ"
      },
      "source": [
        "顾名思义，线性回归解决了回归问题。换句话说，目标是建立一个系统，该系统可以将向量$𝒙∈ℝ^n$作为输入，并预测标量$y∈ℝ$的值作为其输出。在线性回归的情况下，输出是输入的线性函数。设$\\hat{y}$为我们的模型预测$y$应取的值。我们将输出定义为："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IB0Nq_uMRa3"
      },
      "source": [
        "$$\n",
        "\\hat{y}=𝒘^T𝒙\n",
        "$$\n",
        "其中，$𝒘∈ℝ^n$是一个向量参数。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqzGHHifMnbY"
      },
      "source": [
        "参数是控制系统行为的值。在这种情况下，$w_i$是我们在将所有特征的贡献相加之前与特征$x_i$相乘的系数。我们可以将$𝒘$视为一组**权重**，它们决定了每个特征如何影响预测。如果特征$x_i$获得正权重$w_i$，则增加该特征的值会增加我们的预测值$\\hat{y}$。如果特征获得负权重，则增加该特征的值会降低我们的预测值。如果特征的权重很大，那么它对预测的影响就很大。如果特征的权重为零，则它对预测没有影响。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR0kLKYFNjFz"
      },
      "source": [
        "因此，我们对任务$T$有一个定义：通过输出$\\hat{y}=𝒘^T𝒙$，根据$𝒙$预测$y$。接下来，我们需要定义我们的性能指标$P$。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEAr3j66N_gc"
      },
      "source": [
        "假设我们有一个包含$m$个示例输入的设计矩阵，我们不会将其用于训练，而仅用于评估模型的性能。我们还有一个回归目标向量，为每个示例提供正确的$y$值。由于此数据集仅用于评估，因此我们将其称为测试集。我们将输入的设计矩阵称为$𝑿^{test}$，将回归目标向量称为$y^{test}$。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co41F802PPI0"
      },
      "source": [
        "衡量模型性能的一种方法是计算模型在测试集上的**均方误差**。如果$\\hat{𝒚}^{test}$给出模型在测试集上的预测，则均方误差由下式给出："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG9ylFPgPsAe"
      },
      "source": [
        "$$\n",
        "\\operatorname{MSE}_{test}=\\frac{1}{m}∑_i(\\hat{𝒚}^{test}-𝒚^{test})_i^2\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjZK3iS8QWOQ"
      },
      "source": [
        "直观地看，当$\\hat{𝒚}^{test}=𝒚^{test}$时，这个误差度量会降至0。\n",
        "我们还可以看到："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49gJw-DSQdGU"
      },
      "source": [
        "$$\n",
        "\\operatorname{MSE}_{test}=\\frac{1}{m}||\\hat{𝒚}^{test}-𝒚^{test}||_2^2\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOXOru8JQzcI"
      },
      "source": [
        "因此，只要预测值和目标值之间的欧几里得距离增加，误差就会增加。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9nBbPNSQ09O"
      },
      "source": [
        "要制作机器学习算法，我们需要设计一种算法，当算法通过观察训练集$(𝑿^{train},𝒚^{train})$获得经验时，该算法将以减少$\\operatorname{MSE}_{test}$的方式改进权重$𝒘$。一种直观的方法（我们将在后面的第 5.5.1 节中说明）就是最小化训练集上的均方误差$\\operatorname{MSE}_{train}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJvlnlq2Rzar"
      },
      "source": [
        "为了最小化$\\operatorname{MSE}_{train}$，我们可以简单地求解其梯度为$\\bf{0}$的位置："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1iNu8YCSPPe"
      },
      "source": [
        "$$\n",
        "∇_{𝒘}\\operatorname{MSE}_{train}=0\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K85wZMWNTBKR"
      },
      "source": [
        "$$\n",
        "⇒∇_{𝒘}\\frac{1}{m}||\\hat{𝒚}^{train}-𝒚^{train}||_2^2=0\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGgR8qafTOaT"
      },
      "source": [
        "$$\n",
        "⇒\\frac{1}{m}∇_{𝒘}||𝑿^{train}𝒘-𝒚^{train}||_2^2=0\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WfSCR_hThqo"
      },
      "source": [
        "$$\n",
        "⇒∇_{𝒘}(𝑿^{train}𝒘-𝒚^{train})^T(𝑿^{train}𝒘-𝒚^{train})=0\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b33r9o2NUTXZ"
      },
      "source": [
        "$$\n",
        "⇒∇_{𝒘}(𝒘^T𝑿^{train(T)}𝑿^{train}𝒘-2𝒘^T𝑿^{train(T)}𝒚^{train}+𝒚^{train(T)}𝒚^{train})=0\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHEdLFZwWGy1"
      },
      "source": [
        "$$\n",
        "⇒2𝑿^{train(T)}𝑿^{train}𝒘-2𝑿^{train(T)}𝒚^{train}=0\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d30jxXW0Wi9_"
      },
      "source": [
        "$$\n",
        "⇒𝒘=(𝑿^{train(T)}𝑿^{train})^{-1}𝑿^{train(T)}𝒚^{train}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE4w9p8XWx-f"
      },
      "source": [
        "上面方程给出其解的方程组称为**正规方程(normal equations)**。上面方程求值构成了一个简单的学习\n",
        "算法。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hlnh9KxW4CD"
      },
      "source": [
        "值得注意的是，术语“线性回归”通常用于指代一个稍微复杂一些的模型，该模型带有一个附加参数——截距项$b$。在这个模型中："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvWVldQ2XVpp"
      },
      "source": [
        "$$\n",
        "\\hat{y}=𝒘^T𝒙+b\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm15YT_NXbgW"
      },
      "source": [
        "从参数到预测的映射仍然是线性函数，但从特征到预测的映射现在是一个仿射函数。这种对仿射函数的扩展意味着模型预测的图仍然看起来像一条线，但它不需要通过原点。除了添加偏差参数$b$，还可以继续使用只有权重的模型，但用一个始终设置为$1$的额外条目来增$𝒙$。与额外$1$条目对应的的权重起着偏差参数的作用。在本书中，我们将经常使用术语“线性”来提及仿射函数。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQDfHCntYD8p"
      },
      "source": [
        "截距项$b$通常称为仿射变换的偏差参数。该术语源于这样的观点：在没有任何输入的情况下，变换的输出会偏向于$b$。该术语不同于统计偏差的概念，在统计偏差中，统计估计算法对某个数量的预期估计不等于真实数量。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbotiQMtYUsV"
      },
      "source": [
        "线性回归当然是一种极其简单且有限的学习算法，但它提供了学习算法如何工作的示例。在后续章节中，我们将描述学习算法设计的一些基本原理，并演示如何使用这些原理构建更复杂的学习算法。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
